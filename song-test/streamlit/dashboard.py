import streamlit as st
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
from sqlalchemy import create_engine, text
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import re
from kafka import KafkaConsumer
import threading
import time
import os
import pytz

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

def get_korean_now():
    """í˜„ì¬ í•œêµ­ ì‹œê°„ì„ ë°˜í™˜"""
    return datetime.now(KST)

def get_korean_time_hours_ago(hours):
    """í˜„ì¬ í•œêµ­ ì‹œê°„ì—ì„œ Nì‹œê°„ ì „ ì‹œê°„ì„ ë°˜í™˜"""
    return get_korean_now() - timedelta(hours=hours)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="NewsDeck - ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ë§¤ë²ˆ ìƒˆë¡œìš´ ì—°ê²° ìƒì„±)"""
    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "postgres"),
            database=os.getenv("DB_NAME", "airflow"),
            user=os.getenv("DB_USER", "airflow"),
            password=os.getenv("DB_PASSWORD", "airflow"),
            port=os.getenv("DB_PORT", "5432"),
            connect_timeout=10
        )
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.close()
        return conn
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def get_sqlalchemy_engine():
    """SQLAlchemy ì—”ì§„ ìƒì„±"""
    try:
        db_url = f"postgresql://{os.getenv('DB_USER', 'airflow')}:{os.getenv('DB_PASSWORD', 'airflow')}@{os.getenv('DB_HOST', 'postgres')}:{os.getenv('DB_PORT', '5432')}/{os.getenv('DB_NAME', 'airflow')}"
        engine = create_engine(db_url, connect_args={"connect_timeout": 10})
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        return engine
    except Exception as e:
        st.error(f"SQLAlchemy ì—”ì§„ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_news_data(hours=24):
    """ìµœê·¼ Nì‹œê°„ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ"""
    # ë¨¼ì € psycopg2ë¡œ í…Œì´ë¸” ì²´í¬ ë° ìƒì„±
    conn = get_db_connection()
    if not conn:
        return pd.DataFrame()
    
    try:
        # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cursor = conn.cursor()
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'news_articles'
            );
        """)
        table_exists = cursor.fetchone()[0]
        
        if not table_exists:
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS news_articles (
                    id SERIAL PRIMARY KEY,
                    keyword VARCHAR(100),
                    title TEXT NOT NULL,
                    link TEXT UNIQUE NOT NULL,
                    description TEXT,
                    pub_date VARCHAR(100),
                    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            conn.commit()
            
            # ìƒ˜í”Œ ë°ì´í„° ì‚½ì…
            cursor.execute("""
                INSERT INTO news_articles (keyword, title, link, description, pub_date) VALUES
                ('IT', 'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ìƒˆë¡œìš´ ëŒíŒŒêµ¬', 'https://example.com/news1', 'AI ê¸°ìˆ ì´ ìƒˆë¡œìš´ ë‹¨ê³„ë¡œ ì§„ì…í–ˆìŠµë‹ˆë‹¤.', '2025-01-15'),
                ('ì£¼ì‹', 'ì¦ì‹œ ìƒìŠ¹ì„¸ ì§€ì†', 'https://example.com/news2', 'ì½”ìŠ¤í”¼ê°€ ì—°ì¼ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.', '2025-01-15'),
                ('AI', 'ChatGPT ìƒˆ ë²„ì „ ì¶œì‹œ', 'https://example.com/news3', 'ë”ìš± í–¥ìƒëœ AI ì„±ëŠ¥ì„ ìë‘í•©ë‹ˆë‹¤.', '2025-01-15')
                ON CONFLICT (link) DO NOTHING;
            """)
            conn.commit()
        
        cursor.close()
        conn.close()
        
        # SQLAlchemyë¡œ ë°ì´í„° ì¡°íšŒ
        engine = get_sqlalchemy_engine()
        if not engine:
            return pd.DataFrame()
        
        # í•œêµ­ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ Nì‹œê°„ ì „ ì‹œê°„ ê³„ì‚°
        korean_time_ago = get_korean_time_hours_ago(hours)
        
        query = f"""
        SELECT 
            id, keyword, title, link, description, 
            pub_date, collected_at, processed_at
        FROM news_articles 
        WHERE collected_at >= '{korean_time_ago.strftime('%Y-%m-%d %H:%M:%S')}'::timestamp
        ORDER BY collected_at DESC
        LIMIT 1000
        """
        
        df = pd.read_sql_query(query, engine)
        engine.dispose()
        return df
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        if conn:
            conn.close()
        return pd.DataFrame()

# í†µê³„ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_statistics():
    """ë‰´ìŠ¤ í†µê³„ ë°ì´í„° ë¡œë“œ"""
    print("=== load_statistics í•¨ìˆ˜ ì‹œì‘ ===")
    conn = get_db_connection()
    if not conn:
        print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        return {}
    
    print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
    
    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        print("ì»¤ì„œ ìƒì„± ì™„ë£Œ")
        
        # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
        print("í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'news_articles'
            ) as table_exists;
        """)
        result_row = cursor.fetchone()
        table_exists = result_row['table_exists']
        print(f"í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€: {table_exists}")
        
        if not table_exists:
            cursor.close()
            conn.close()
            print("í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ - ê¸°ë³¸ê°’ ë°˜í™˜")
            return {
                'overall': {'total_articles': 0, 'total_keywords': 0, 'last_update': None},
                'daily': {'daily_articles': 0, 'daily_keywords': 0},
                'keywords': [],
                'hourly_trend': []
            }
        
        print("ì „ì²´ í†µê³„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        # ì „ì²´ í†µê³„
        cursor.execute("""
            SELECT 
                COUNT(*) as total_articles,
                COUNT(DISTINCT keyword) as total_keywords,
                MAX(collected_at) as last_update
            FROM news_articles
        """)
        overall_stats = cursor.fetchone()
        print(f"ì „ì²´ í†µê³„ ê²°ê³¼: {dict(overall_stats) if overall_stats else 'None'}")
        
        print("24ì‹œê°„ í†µê³„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        # 24ì‹œê°„ í†µê³„ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        korean_24h_ago = get_korean_time_hours_ago(24)
        cursor.execute(f"""
            SELECT 
                COUNT(*) as daily_articles,
                COUNT(DISTINCT keyword) as daily_keywords
            FROM news_articles 
            WHERE collected_at >= '{korean_24h_ago.strftime('%Y-%m-%d %H:%M:%S')}'::timestamp
        """)
        daily_stats = cursor.fetchone()
        print(f"24ì‹œê°„ í†µê³„ ê²°ê³¼: {dict(daily_stats) if daily_stats else 'None'}")
        
        print("í‚¤ì›Œë“œë³„ í†µê³„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        # í‚¤ì›Œë“œë³„ í†µê³„ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        cursor.execute(f"""
            SELECT 
                keyword, 
                COUNT(*) as count,
                MAX(collected_at) as last_collected
            FROM news_articles 
            WHERE collected_at >= '{korean_24h_ago.strftime('%Y-%m-%d %H:%M:%S')}'::timestamp
            GROUP BY keyword 
            ORDER BY count DESC
            LIMIT 20
        """)
        keyword_stats = cursor.fetchall()
        print(f"í‚¤ì›Œë“œ í†µê³„ ê²°ê³¼ ê°œìˆ˜: {len(keyword_stats)}")
        
        print("ì‹œê°„ë³„ íŠ¸ë Œë“œ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
        # ì‹œê°„ë³„ ìˆ˜ì§‘ íŠ¸ë Œë“œ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        cursor.execute(f"""
            SELECT 
                DATE_TRUNC('hour', collected_at) as hour,
                COUNT(*) as count
            FROM news_articles 
            WHERE collected_at >= '{korean_24h_ago.strftime('%Y-%m-%d %H:%M:%S')}'::timestamp
            GROUP BY hour 
            ORDER BY hour
        """)
        hourly_trend = cursor.fetchall()
        print(f"ì‹œê°„ë³„ íŠ¸ë Œë“œ ê²°ê³¼ ê°œìˆ˜: {len(hourly_trend)}")
        
        cursor.close()
        conn.close()
        
        result = {
            'overall': dict(overall_stats) if overall_stats else {},
            'daily': dict(daily_stats) if daily_stats else {},
            'keywords': [dict(row) for row in keyword_stats],
            'hourly_trend': [dict(row) for row in hourly_trend]
        }
        
        print(f"ìµœì¢… result ìƒì„± ì™„ë£Œ: {result}")
        print("=== load_statistics í•¨ìˆ˜ ì¢…ë£Œ ===")
        return result
        
    except Exception as e:
        import traceback
        print(f"í†µê³„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        print(f"ì˜ˆì™¸ íƒ€ì…: {type(e)}")
        print(f"ì˜ˆì™¸ ìƒì„¸: {traceback.format_exc()}")
        st.error(f"í†µê³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        if conn:
            conn.close()
        return {}

# ì‹¤ì‹œê°„ Kafka ì†Œë¹„ì (ë°±ê·¸ë¼ìš´ë“œ)
def kafka_consumer_thread():
    """Kafkaì—ì„œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì†Œë¹„"""
    try:
        consumer = KafkaConsumer(
            'news-topic',
            bootstrap_servers=['kafka:9092'],
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            auto_offset_reset='latest'
        )
        
        for message in consumer:
            # ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            if 'realtime_news' not in st.session_state:
                st.session_state.realtime_news = []
            
            st.session_state.realtime_news.append(message.value)
            
            # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            if len(st.session_state.realtime_news) > 10:
                st.session_state.realtime_news = st.session_state.realtime_news[-10:]
                
    except Exception as e:
        st.error(f"Kafka ì—°ê²° ì‹¤íŒ¨: {e}")

# ë©”ì¸ ëŒ€ì‹œë³´ë“œ UI
def main():
    # í—¤ë”
    st.title("ğŸ“° NewsDeck - ì‹¤ì‹œê°„ ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ")
    
    # í˜„ì¬ í•œêµ­ ì‹œê°„ í‘œì‹œ
    current_korean_time = get_korean_now()
    st.markdown(f"**í˜„ì¬ ì‹œê°„ (KST):** {current_korean_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("âš™ï¸ ì„¤ì •")
    
    # ì‹œê°„ ë²”ìœ„ ì„ íƒ
    time_range = st.sidebar.selectbox(
        "ë°ì´í„° ì¡°íšŒ ë²”ìœ„",
        options=[1, 6, 12, 24, 48],
        index=3,
        format_func=lambda x: f"ìµœê·¼ {x}ì‹œê°„"
    )
    
    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
    auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=False)
    if auto_refresh:
        time.sleep(30)
        st.rerun()
    
    # ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()
    
    # í†µê³„ ë°ì´í„° ë¡œë“œ
    stats = load_statistics()
    
    # KPI ë©”íŠ¸ë¦­ í‘œì‹œ
    if stats:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì „ì²´ ìˆ˜ì§‘ ë‰´ìŠ¤",
                stats.get('overall', {}).get('total_articles', 0),
                delta=stats.get('daily', {}).get('daily_articles', 0)
            )
        
        with col2:
            st.metric(
                "ì˜¤ëŠ˜ ìˆ˜ì§‘ ë‰´ìŠ¤",
                stats.get('daily', {}).get('daily_articles', 0)
            )
        
        with col3:
            st.metric(
                "ì¶”ì  í‚¤ì›Œë“œ",
                stats.get('overall', {}).get('total_keywords', 0)
            )
        
        with col4:
            last_update = stats.get('overall', {}).get('last_update')
            if last_update:
                # UTC ì‹œê°„ì„ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                if last_update.tzinfo is None:
                    # naive datetimeì„ UTCë¡œ ê°€ì •í•˜ê³  í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                    last_update_utc = pytz.UTC.localize(last_update)
                    last_update_kst = last_update_utc.astimezone(KST)
                else:
                    last_update_kst = last_update.astimezone(KST)
                st.metric("ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ (KST)", last_update_kst.strftime("%H:%M"))
    
    st.markdown("---")
    
    # ë©”ì¸ ì½˜í…ì¸  íƒ­
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“° ë‰´ìŠ¤ ëª©ë¡", "ğŸ“ˆ ë¶„ì„", "âš¡ ì‹¤ì‹œê°„"])
    
    with tab1:
        # í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ ì°¨íŠ¸
        if stats and stats.get('keywords'):
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ (24ì‹œê°„)")
                keyword_df = pd.DataFrame(stats['keywords'])
                
                fig = px.bar(
                    keyword_df,
                    x='keyword',
                    y='count',
                    title="í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ í˜„í™©",
                    color='count',
                    color_continuous_scale='Blues'
                )
                fig.update_layout(showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.subheader("í‚¤ì›Œë“œ ë¶„í¬")
                fig = px.pie(
                    keyword_df,
                    values='count',
                    names='keyword',
                    title="í‚¤ì›Œë“œë³„ ë¹„ìœ¨"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        # ì‹œê°„ë³„ ìˆ˜ì§‘ íŠ¸ë Œë“œ
        if stats and stats.get('hourly_trend'):
            st.subheader("ì‹œê°„ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ íŠ¸ë Œë“œ (24ì‹œê°„)")
            trend_df = pd.DataFrame(stats['hourly_trend'])
            trend_df['hour'] = pd.to_datetime(trend_df['hour'])
            
            fig = px.line(
                trend_df,
                x='hour',
                y='count',
                title="ì‹œê°„ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ëŸ‰",
                markers=True
            )
            fig.update_layout(xaxis_title="ì‹œê°„", yaxis_title="ë‰´ìŠ¤ ìˆ˜")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader(f"ğŸ“° ìµœê·¼ {time_range}ì‹œê°„ ë‰´ìŠ¤ ëª©ë¡")
        
        # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
        news_df = load_news_data(time_range)
        
        if not news_df.empty:
            # í•„í„°ë§ ì˜µì…˜
            col1, col2 = st.columns(2)
            with col1:
                selected_keywords = st.multiselect(
                    "í‚¤ì›Œë“œ í•„í„°",
                    options=news_df['keyword'].unique(),
                    default=news_df['keyword'].unique()
                )
            
            with col2:
                search_text = st.text_input("ì œëª© ê²€ìƒ‰", "")
            
            # í•„í„° ì ìš©
            filtered_df = news_df[news_df['keyword'].isin(selected_keywords)]
            if search_text:
                filtered_df = filtered_df[
                    filtered_df['title'].str.contains(search_text, case=False, na=False)
                ]
            
            st.info(f"ì´ {len(filtered_df)}ê°œì˜ ë‰´ìŠ¤ê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
            for idx, row in filtered_df.iterrows():
                with st.container():
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.markdown(f"**[{row['keyword']}] {row['title']}**")
                        st.markdown(f"{row['description'][:200]}...")
                        st.markdown(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({row['link']})")
                    
                    with col2:
                        st.markdown(f"**ìˆ˜ì§‘ ì‹œê°„**")
                        st.markdown(f"{row['collected_at'].strftime('%m-%d %H:%M')}")
                    
                    st.markdown("---")
        else:
            st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab3:
        st.subheader("ğŸ“ˆ ë‰´ìŠ¤ ë¶„ì„")
        
        if not news_df.empty:
            # ì¼ë³„ ìˆ˜ì§‘ íŠ¸ë Œë“œ
            news_df['date'] = pd.to_datetime(news_df['collected_at']).dt.date
            daily_counts = news_df.groupby(['date', 'keyword']).size().reset_index(name='count')
            
            fig = px.line(
                daily_counts,
                x='date',
                y='count',
                color='keyword',
                title="ì¼ë³„ í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ íŠ¸ë Œë“œ"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # í‚¤ì›Œë“œ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
            keyword_pivot = news_df.pivot_table(
                index=news_df['collected_at'].dt.hour,
                columns='keyword',
                values='id',
                aggfunc='count',
                fill_value=0
            )
            
            if not keyword_pivot.empty:
                fig = px.imshow(
                    keyword_pivot.corr(),
                    title="í‚¤ì›Œë“œ ê°„ ìˆ˜ì§‘ íŒ¨í„´ ìƒê´€ê´€ê³„",
                    aspect="auto"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.subheader("âš¡ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¼")
        
        # ì‹¤ì‹œê°„ ë‰´ìŠ¤ í‘œì‹œ
        if 'realtime_news' in st.session_state and st.session_state.realtime_news:
            st.success("ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¼ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            for news in reversed(st.session_state.realtime_news):
                with st.container():
                    st.markdown(f"**[{news.get('keyword', 'Unknown')}] {news.get('title', 'No Title')}**")
                    st.markdown(f"{news.get('description', 'No Description')[:150]}...")
                    st.markdown(f"ìˆ˜ì§‘ ì‹œê°„: {news.get('collected_at', 'Unknown')}")
                    st.markdown("---")
        else:
            st.info("ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
            
            # Kafka ì—°ê²° ìƒíƒœ í™•ì¸
            if st.button("Kafka ì—°ê²° í…ŒìŠ¤íŠ¸"):
                try:
                    # ê°„ë‹¨í•œ Kafka ì—°ê²° í…ŒìŠ¤íŠ¸
                    consumer = KafkaConsumer(
                        bootstrap_servers=['kafka:9092'],
                        consumer_timeout_ms=1000
                    )
                    consumer.close()
                    st.success("Kafka ì—°ê²° ì„±ê³µ!")
                except Exception as e:
                    st.error(f"Kafka ì—°ê²° ì‹¤íŒ¨: {e}")

# ë°±ê·¸ë¼ìš´ë“œ Kafka ì†Œë¹„ì ì‹œì‘
if 'kafka_started' not in st.session_state:
    st.session_state.kafka_started = True
    kafka_thread = threading.Thread(target=kafka_consumer_thread, daemon=True)
    kafka_thread.start()

if __name__ == "__main__":
    main()