import streamlit as st
import pandas as pd
from sqlalchemy import create_engine, text
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import time
import os
import pytz
from typing import Dict, List, Optional

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="NewsDeck - í†µí•© ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ì»¤ìŠ¤í…€ CSS
st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
    }
    .status-good { color: #28a745; }
    .status-warning { color: #ffc107; }
    .status-error { color: #dc3545; }
</style>
""",
    unsafe_allow_html=True,
)


class IntegratedNewsDashboard:
    """
    í†µí•© ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ
    - song-testì˜ ê³ ë„í™”ëœ ê¸°ëŠ¥ ê¸°ë°˜
    - seoyunjangì˜ ê°„ê²°í•œ êµ¬ì¡° ì°¸ê³ 
    """

    def __init__(self):
        self.db_config = {
            "host": os.getenv("DB_HOST", "localhost"),
            "database": os.getenv("DB_NAME", "airflow"),
            "user": os.getenv("DB_USER", "airflow"),
            "password": os.getenv("DB_PASSWORD", "airflow"),
            "port": os.getenv("DB_PORT", "5432"),
        }

        # ë°ì´í„°ë² ì´ìŠ¤ URL ìƒì„±
        self.db_url = f"postgresql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
        self.kst = pytz.timezone("Asia/Seoul")

    @st.cache_resource(ttl=300)
    def get_db_engine(_self):
        """SQLAlchemy ì—”ì§„ ìƒì„± ë° ìºì‹±"""
        try:
            engine = create_engine(_self.db_url)
            return engine
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            return None

    @st.cache_data(ttl=60)
    def load_news_data(_self, hours: int = 24, limit: int = 1000) -> pd.DataFrame:
        """ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ"""
        try:
            engine = _self.get_db_engine()
            if engine is None:
                return pd.DataFrame()

            query = f"""
            SELECT 
                id, keyword, title, link, description, 
                pub_date, collected_at, processed_at, created_at
            FROM news_articles 
            WHERE collected_at >= NOW() - INTERVAL '{hours} hours'
            ORDER BY collected_at DESC
            LIMIT {limit}
            """

            df = pd.read_sql_query(query, engine)

            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ (í•œêµ­ ì‹œê°„ëŒ€ ì ìš©)
            if not df.empty:
                for col in ["collected_at", "processed_at", "created_at"]:
                    if col in df.columns:
                        df[col] = pd.to_datetime(df[col])
                        # UTCì—ì„œ í•œêµ­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
                        if df[col].dt.tz is None:
                            df[col] = (
                                df[col].dt.tz_localize("UTC").dt.tz_convert(_self.kst)
                            )
                        else:
                            df[col] = df[col].dt.tz_convert(_self.kst)

            return df

        except Exception as e:
            st.error(f"ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    @st.cache_data(ttl=60)
    def load_statistics(_self) -> Dict:
        """í†µê³„ ë°ì´í„° ë¡œë“œ"""
        try:
            engine = _self.get_db_engine()
            if engine is None:
                return {}

            with engine.connect() as conn:
                # ì „ì²´ í†µê³„
                overall_query = """
                    SELECT 
                        COUNT(*) as total_articles,
                        COUNT(DISTINCT keyword) as total_keywords,
                        MAX(collected_at) as last_update
                    FROM news_articles
                """
                overall_result = conn.execute(text(overall_query)).fetchone()
                overall_stats = dict(overall_result._mapping) if overall_result else {}

                # 24ì‹œê°„ í†µê³„
                daily_query = """
                    SELECT 
                        COUNT(*) as daily_articles,
                        COUNT(DISTINCT keyword) as daily_keywords
                    FROM news_articles 
                    WHERE collected_at >= NOW() - INTERVAL '24 hours'
                """
                daily_result = conn.execute(text(daily_query)).fetchone()
                daily_stats = dict(daily_result._mapping) if daily_result else {}

                # í‚¤ì›Œë“œë³„ í†µê³„
                keyword_query = """
                    SELECT 
                        keyword, 
                        COUNT(*) as count,
                        MAX(collected_at) as last_collected
                    FROM news_articles 
                    WHERE collected_at >= NOW() - INTERVAL '24 hours'
                    GROUP BY keyword 
                    ORDER BY count DESC
                    LIMIT 20
                """
                keyword_results = conn.execute(text(keyword_query)).fetchall()
                keyword_stats = [dict(row._mapping) for row in keyword_results]

                # ì‹œê°„ëŒ€ë³„ í†µê³„ (í•œêµ­ ì‹œê°„ëŒ€ ê¸°ì¤€)
                hourly_query = """
                    SELECT 
                        DATE_TRUNC('hour', collected_at AT TIME ZONE 'UTC' AT TIME ZONE 'Asia/Seoul') as hour,
                        COUNT(*) as count
                    FROM news_articles 
                    WHERE collected_at >= NOW() - INTERVAL '24 hours'
                    GROUP BY DATE_TRUNC('hour', collected_at AT TIME ZONE 'UTC' AT TIME ZONE 'Asia/Seoul')
                    ORDER BY hour
                """
                hourly_results = conn.execute(text(hourly_query)).fetchall()
                hourly_stats = [dict(row._mapping) for row in hourly_results]

            engine.dispose()

            return {
                "overall": overall_stats,
                "daily": daily_stats,
                "keywords": keyword_stats,
                "hourly": hourly_stats,
            }

        except Exception as e:
            st.error(f"í†µê³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    @st.cache_data(ttl=300)
    def load_system_logs(_self, limit: int = 50) -> pd.DataFrame:
        """ì‹œìŠ¤í…œ ë¡œê·¸ ë¡œë“œ"""
        try:
            engine = _self.get_db_engine()
            if engine is None:
                return pd.DataFrame()

            query = f"""
            SELECT level, message, component, timestamp
            FROM system_logs 
            ORDER BY timestamp DESC
            LIMIT {limit}
            """

            df = pd.read_sql_query(query, engine)

            if not df.empty:
                df["timestamp"] = pd.to_datetime(df["timestamp"])
                # UTCì—ì„œ í•œêµ­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜
                if df["timestamp"].dt.tz is None:
                    df["timestamp"] = (
                        df["timestamp"].dt.tz_localize("UTC").dt.tz_convert(_self.kst)
                    )
                else:
                    df["timestamp"] = df["timestamp"].dt.tz_convert(_self.kst)

            return df

        except Exception as e:
            # ì‹œìŠ¤í…œ ë¡œê·¸ í…Œì´ë¸”ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—ëŸ¬ë¥¼ ì¡°ìš©íˆ ì²˜ë¦¬
            return pd.DataFrame()

    def render_header(self):
        """í—¤ë” ë Œë”ë§"""
        st.markdown(
            '<h1 class="main-header">ğŸ“° NewsDeck í†µí•© ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ</h1>',
            unsafe_allow_html=True,
        )
        st.markdown("---")

    def render_sidebar(self) -> Dict:
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        st.sidebar.header("ğŸ› ï¸ ëŒ€ì‹œë³´ë“œ ì„¤ì •")

        # ì‹œê°„ ë²”ìœ„ ì„ íƒ
        time_range = st.sidebar.selectbox(
            "ğŸ“… ì‹œê°„ ë²”ìœ„",
            options=[1, 6, 12, 24, 48, 72],
            index=3,  # 24ì‹œê°„ ê¸°ë³¸ê°’
            format_func=lambda x: f"ìµœê·¼ {x}ì‹œê°„",
        )

        # ìë™ ìƒˆë¡œê³ ì¹¨
        auto_refresh = st.sidebar.checkbox("ğŸ”„ ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=False)

        # í‚¤ì›Œë“œ í•„í„°
        keywords_filter = st.sidebar.text_input(
            "ğŸ” í‚¤ì›Œë“œ í•„í„° (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: AI, ì£¼ì‹, IT"
        )

        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.sidebar.button("ğŸ”„ ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            st.cache_data.clear()
            st.rerun()

        # ìë™ ìƒˆë¡œê³ ì¹¨ ê°œì„  (ê¹œë°•ì„ ë°©ì§€)
        if auto_refresh:
            # ì„¸ì…˜ ìƒíƒœë¡œ ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨ ì‹œê°„ ì¶”ì 
            if "last_refresh" not in st.session_state:
                st.session_state.last_refresh = time.time()

            current_time = time.time()
            if current_time - st.session_state.last_refresh >= 30:
                st.session_state.last_refresh = current_time
                st.rerun()

        return {
            "time_range": time_range,
            "auto_refresh": auto_refresh,
            "keywords_filter": (
                [k.strip() for k in keywords_filter.split(",") if k.strip()]
                if keywords_filter
                else []
            ),
        }

    def render_key_metrics(self, stats: Dict):
        """ì£¼ìš” ì§€í‘œ ë Œë”ë§"""
        st.subheader("ğŸ“Š ì£¼ìš” ì§€í‘œ")

        overall = stats.get("overall", {})
        daily = stats.get("daily", {})

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_articles = overall.get("total_articles", 0)
            st.metric(
                label="ì´ ë‰´ìŠ¤ ê¸°ì‚¬",
                value=f"{total_articles:,}",
                help="ì „ì²´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜",
            )

        with col2:
            daily_articles = daily.get("daily_articles", 0)
            st.metric(
                label="24ì‹œê°„ ìˆ˜ì§‘",
                value=f"{daily_articles:,}",
                help="ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ë‰´ìŠ¤",
            )

        with col3:
            total_keywords = overall.get("total_keywords", 0)
            st.metric(
                label="ì „ì²´ í‚¤ì›Œë“œ",
                value=f"{total_keywords:,}",
                help="ìˆ˜ì§‘ ì¤‘ì¸ ì „ì²´ í‚¤ì›Œë“œ ìˆ˜",
            )

        with col4:
            last_update = overall.get("last_update")
            if last_update:
                # UTCì—ì„œ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                last_update_kst = (
                    pd.to_datetime(last_update).tz_localize("UTC").tz_convert(self.kst)
                )
                last_update_str = last_update_kst.strftime("%H:%M")
                status = (
                    "ğŸŸ¢ ì •ìƒ"
                    if last_update_kst > datetime.now(self.kst) - timedelta(hours=1)
                    else "ğŸŸ¡ ì§€ì—°"
                )
            else:
                last_update_str = "ì—†ìŒ"
                status = "ğŸ”´ ì¤‘ë‹¨"

            st.metric(
                label="ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸",
                value=last_update_str,
                delta=status,
                help="ê°€ì¥ ìµœê·¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œê°„ (í•œêµ­ ì‹œê°„)",
            )

    def render_keyword_analysis(self, stats: Dict, filters: Dict):
        """í‚¤ì›Œë“œ ë¶„ì„ ë Œë”ë§"""
        st.subheader("ğŸ” í‚¤ì›Œë“œë³„ ë¶„ì„")

        keywords_data = stats.get("keywords", [])
        if not keywords_data:
            st.info("í‘œì‹œí•  í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # í•„í„° ì ìš©
        if filters["keywords_filter"]:
            keywords_data = [
                item
                for item in keywords_data
                if item["keyword"] in filters["keywords_filter"]
            ]

        if not keywords_data:
            st.warning("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_keywords = pd.DataFrame(keywords_data)

        col1, col2 = st.columns(2)

        with col1:
            # í‚¤ì›Œë“œë³„ ìˆ˜ì§‘ëŸ‰ ë°” ì°¨íŠ¸
            fig_bar = px.bar(
                df_keywords.head(10),
                x="keyword",
                y="count",
                title="í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ëŸ‰ (Top 10)",
                color="count",
                color_continuous_scale="blues",
            )
            fig_bar.update_layout(
                xaxis_title="í‚¤ì›Œë“œ", yaxis_title="ë‰´ìŠ¤ ìˆ˜", showlegend=False
            )
            st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            # í‚¤ì›Œë“œë³„ ìˆ˜ì§‘ëŸ‰ íŒŒì´ ì°¨íŠ¸
            fig_pie = px.pie(
                df_keywords.head(8),
                values="count",
                names="keyword",
                title="í‚¤ì›Œë“œë³„ ë¹„ìœ¨ (Top 8)",
            )
            st.plotly_chart(fig_pie, use_container_width=True)

        # ìƒì„¸ í‚¤ì›Œë“œ í…Œì´ë¸”
        st.subheader("ğŸ“‹ í‚¤ì›Œë“œë³„ ìƒì„¸ ì •ë³´")

        display_df = df_keywords.copy()
        # í•œêµ­ ì‹œê°„ëŒ€ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
        display_df["last_collected"] = (
            pd.to_datetime(display_df["last_collected"])
            .dt.tz_localize("UTC")
            .dt.tz_convert(self.kst)
            .dt.strftime("%Y-%m-%d %H:%M")
        )
        display_df = display_df.rename(
            columns={
                "keyword": "í‚¤ì›Œë“œ",
                "count": "ìˆ˜ì§‘ëŸ‰",
                "last_collected": "ë§ˆì§€ë§‰ ìˆ˜ì§‘ (KST)",
            }
        )

        # ê³ ì • ë†’ì´ë¡œ í…Œì´ë¸” ì•ˆì •í™” (ê¹œë°•ì„ ë°©ì§€)
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True,
            height=300,  # ê³ ì • ë†’ì´ ì„¤ì •
        )

    def render_time_series(self, stats: Dict):
        """ì‹œê³„ì—´ ë¶„ì„ ë Œë”ë§"""
        st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ìˆ˜ì§‘ íŠ¸ë Œë“œ")

        hourly_data = stats.get("hourly", [])
        if not hourly_data:
            st.info("í‘œì‹œí•  ì‹œê°„ëŒ€ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„°í”„ë ˆì„ ìƒì„± (í•œêµ­ ì‹œê°„ëŒ€ ì ìš©)
        df_hourly = pd.DataFrame(hourly_data)
        if not df_hourly.empty:
            df_hourly["hour"] = pd.to_datetime(df_hourly["hour"])
            # ì´ë¯¸ PostgreSQLì—ì„œ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ KSTë¡œ í‘œì‹œë§Œ í•˜ë©´ ë¨
            df_hourly["hour_kst"] = df_hourly["hour"]

        # ì‹œê³„ì—´ ì°¨íŠ¸ (í•œêµ­ ì‹œê°„ í‘œì‹œ)
        fig_time = px.line(
            df_hourly,
            x="hour_kst",
            y="count",
            title="ì‹œê°„ëŒ€ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ëŸ‰ (KST)",
            markers=True,
        )
        fig_time.update_layout(
            xaxis_title="ì‹œê°„ (KST)", yaxis_title="ë‰´ìŠ¤ ìˆ˜", hovermode="x unified"
        )
        fig_time.update_traces(line=dict(color="#1f77b4", width=3), marker=dict(size=8))

        st.plotly_chart(fig_time, use_container_width=True)

        # ì‹œê°„ëŒ€ë³„ í†µê³„
        if len(df_hourly) > 1:
            avg_per_hour = df_hourly["count"].mean()
            max_hour = df_hourly.loc[df_hourly["count"].idxmax()]
            min_hour = df_hourly.loc[df_hourly["count"].idxmin()]

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì‹œê°„ë‹¹ í‰ê· ", f"{avg_per_hour:.1f}ê±´")
            with col2:
                st.metric(
                    "ìµœê³  ìˆ˜ì§‘ ì‹œê°„",
                    f"{max_hour['hour_kst'].strftime('%Hì‹œ')} (KST)",
                    f"{max_hour['count']}ê±´",
                )
            with col3:
                st.metric(
                    "ìµœì € ìˆ˜ì§‘ ì‹œê°„",
                    f"{min_hour['hour_kst'].strftime('%Hì‹œ')} (KST)",
                    f"{min_hour['count']}ê±´",
                )

    def render_recent_news(self, df: pd.DataFrame, filters: Dict):
        """ìµœê·¼ ë‰´ìŠ¤ ëª©ë¡ ë Œë”ë§"""
        st.subheader("ğŸ“° ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤")

        if df.empty:
            st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # í•„í„° ì ìš©
        filtered_df = df.copy()
        if filters["keywords_filter"]:
            filtered_df = filtered_df[
                filtered_df["keyword"].isin(filters["keywords_filter"])
            ]

        if filtered_df.empty:
            st.warning("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë‰´ìŠ¤ ê°œìˆ˜ ì„ íƒ
        num_news = st.selectbox("í‘œì‹œí•  ë‰´ìŠ¤ ìˆ˜", [10, 20, 50, 100], index=1)

        # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
        for idx, row in filtered_df.head(num_news).iterrows():
            with st.expander(
                (
                    f"[{row['keyword']}] {row['title'][:80]}..."
                    if len(row["title"]) > 80
                    else f"[{row['keyword']}] {row['title']}"
                ),
                expanded=False,
            ):
                col1, col2 = st.columns([3, 1])

                with col1:
                    st.write(f"**ì œëª©:** {row['title']}")
                    if row["description"]:
                        st.write(
                            f"**ë‚´ìš©:** {row['description'][:200]}..."
                            if len(row["description"]) > 200
                            else f"**ë‚´ìš©:** {row['description']}"
                        )
                    st.write(f"**ë§í¬:** [ë‰´ìŠ¤ ë³´ê¸°]({row['link']})")

                with col2:
                    st.write(f"**í‚¤ì›Œë“œ:** {row['keyword']}")
                    # í•œêµ­ ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
                    if pd.notnull(row["collected_at"]):
                        collected_time = row["collected_at"]
                        if hasattr(collected_time, "tz_localize"):
                            # ì´ë¯¸ ì‹œê°„ëŒ€ê°€ ì ìš©ëœ ê²½ìš°
                            time_str = collected_time.strftime("%m-%d %H:%M (KST)")
                        else:
                            time_str = collected_time.strftime("%m-%d %H:%M (KST)")
                        st.write(f"**ìˆ˜ì§‘ì‹œê°„:** {time_str}")
                    if row["pub_date"]:
                        st.write(f"**ë°œí–‰ì¼:** {row['pub_date']}")

    def render_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ë Œë”ë§"""
        st.subheader("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")

        # ì‹œìŠ¤í…œ ë¡œê·¸ ë¡œë“œ
        logs_df = self.load_system_logs()

        if not logs_df.empty:
            # ìµœê·¼ ë¡œê·¸ ìƒíƒœ ë¶„ì„
            recent_logs = logs_df.head(10)
            error_count = len(recent_logs[recent_logs["level"] == "ERROR"])
            warning_count = len(recent_logs[recent_logs["level"] == "WARNING"])

            col1, col2, col3 = st.columns(3)

            with col1:
                status_color = "ğŸŸ¢" if error_count == 0 else "ğŸ”´"
                st.metric(
                    "ì‹œìŠ¤í…œ ìƒíƒœ",
                    f"{status_color} {'ì •ìƒ' if error_count == 0 else 'ì˜¤ë¥˜'}",
                )

            with col2:
                st.metric("ìµœê·¼ ê²½ê³ ", f"{warning_count}ê±´")

            with col3:
                st.metric("ìµœê·¼ ì˜¤ë¥˜", f"{error_count}ê±´")

            # ìµœê·¼ ë¡œê·¸ ëª©ë¡
            with st.expander("ğŸ“‹ ìµœê·¼ ì‹œìŠ¤í…œ ë¡œê·¸", expanded=False):
                for _, log in recent_logs.iterrows():
                    level_color = {"INFO": "ğŸŸ¦", "WARNING": "ğŸŸ¨", "ERROR": "ğŸŸ¥"}.get(
                        log["level"], "â¬œ"
                    )

                    st.write(
                        f"{level_color} **[{log['component']}]** {log['message']} - {log['timestamp'].strftime('%m-%d %H:%M:%S (KST)')}"
                    )
        else:
            st.info("ì‹œìŠ¤í…œ ë¡œê·¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def run(self):
        """ë©”ì¸ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰"""
        self.render_header()

        # ì‚¬ì´ë“œë°” ì„¤ì •
        filters = self.render_sidebar()

        # ë°ì´í„° ë¡œë“œ
        with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            stats = self.load_statistics()
            news_df = self.load_news_data(hours=filters["time_range"])

        # ì£¼ìš” ì§€í‘œ
        self.render_key_metrics(stats)

        st.markdown("---")

        # í‚¤ì›Œë“œ ë¶„ì„
        self.render_keyword_analysis(stats, filters)

        st.markdown("---")

        # ì‹œê³„ì—´ ë¶„ì„
        self.render_time_series(stats)

        st.markdown("---")

        # ìµœê·¼ ë‰´ìŠ¤
        self.render_recent_news(news_df, filters)

        st.markdown("---")

        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.render_system_status()

        # í‘¸í„° (í•œêµ­ ì‹œê°„ í‘œì‹œ)
        st.markdown("---")
        kst_time = datetime.now(self.kst)
        st.markdown(
            """
            <div style='text-align: center; color: #666; margin-top: 2rem;'>
                <p>ğŸ“° NewsDeck í†µí•© ë‰´ìŠ¤ ëŒ€ì‹œë³´ë“œ | ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œ</p>
                <p>ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {} (KST)</p>
            </div>
            """.format(
                kst_time.strftime("%Y-%m-%d %H:%M:%S")
            ),
            unsafe_allow_html=True,
        )


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        dashboard = IntegratedNewsDashboard()
        dashboard.run()
    except Exception as e:
        st.error(f"ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
